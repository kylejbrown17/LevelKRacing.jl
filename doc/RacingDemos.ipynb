{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8e6e6eef-aa56-4bb6-be8a-03718a8373d4"
    }
   },
   "source": [
    "# Level K Racing\n",
    "\n",
    "This notebook gives a few visual examples of what's going on under the hood when the cars are racing. You'll need to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "6db4d148-6d9c-4efe-ade5-52ad8191cb6f"
    }
   },
   "outputs": [],
   "source": [
    "using AutomotiveDrivingModels\n",
    "using AutoViz\n",
    "using Reactive\n",
    "using Interact\n",
    "using NearestNeighbors\n",
    "using LevelKRacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e10ecf17-eddd-4ff1-b148-a75f1e58a4d7"
    }
   },
   "outputs": [],
   "source": [
    "# scene parameters\n",
    "scene = Scene()\n",
    "framerate = 24\n",
    "Δt = 1.0/framerate # size of rendering timesteps\n",
    "n_integration_sub_steps = 3 # sub steps for smoother integration\n",
    "context = IntegratedContinuous(Δt, n_integration_sub_steps) # integrated continuous context\n",
    "\n",
    "#car parameters\n",
    "car_length = 4.8 # front wheel to back wheel\n",
    "car_width = 2.5\n",
    "v⁰  = 0.0 # initial velocity\n",
    "δ⁰ = 0.0 # initial steering angle\n",
    "\n",
    "############### INITIALIZE TRACK ################\n",
    "lane_width = 30.0\n",
    "radius = 45.0\n",
    "edge_buffer = 0.25\n",
    "T_MAX= lane_width/2.0 - car_width/2.0 - edge_buffer # max allowable projection distance from center of lane\n",
    "base_speed= 0.0\n",
    "\n",
    "# spline control points\n",
    "# Pts = 50*[0 -1 -2 -3 -3.5 -3 -2 -1 -0.5 -1 -2 -3 -4 -5 -6 -6.5 -6 -5.5 -6 -6 -5 -4 -3 -2 -1.5 -1 0 1 1.5 2 3 4 5 6 6 6 7 7 7 7 6 5 4 4 4 3 2 1 0; \n",
    "#        0 0 0 0 -1 -2 -2 -2 -3 -4 -4 -4 -4 -4 -4 -3 -2 -1 0 1 2 3 4 4 3 2 2 2 3 4 4 4 4 3 2 1 0 -1 -2 -3 -4 -4 -3 -2 -1 0 0 0 0]\n",
    "Pts = 50*[0 -1 -2 -3 -3.5 -3 -2 -1 -0.5 -1 -2 -3 -4 -5 -6 -6.5 -6 -5.5 -6 -6 -5 -4 -3 -2 -1.5 -1 0 1 1.5 2 3 4 5 6.25 7 7 7 7 7 7 7 6 5 4 4 4 3 2 1 0; \n",
    "       0 0 0 0 -1 -2 -2 -2 -3 -4 -4 -4 -4 -4 -4 -3 -2 -1 0 1 2 3 4 4 3 2 2 2 3 4 4 4 4 4 3 2 1 0 -1 -2 -3 -4 -4 -3 -2 -1 0 0 0 0]\n",
    "degree = 3 # degree of spline\n",
    "num_points = 10001\n",
    "num_samples = 420\n",
    "\n",
    "track = Raceway(Pts,degree,num_points,num_samples,lane_width)\n",
    "track;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "ef9c8b92-a894-42ce-a7cd-afbc480cc18d"
    }
   },
   "outputs": [],
   "source": [
    "carcolors = Dict{Int, Colorant}()\n",
    "\n",
    "track.models[1] = HRHC(1,track.roadway,context,h=12,v_max=120.0,μ=30.0,a_step=12.0,a_range=[-1,0,1],k=2)\n",
    "track.models[1].v_cmd = 80\n",
    "v₁ = track.models[1].v_range[track.models[1].v_cmd]\n",
    "vehstate1 = VehicleState(VecSE2(-150,-80,-1.1), track.roadway, v₁)\n",
    "vehdef1 = VehicleDef(1,AgentClass.CAR, car_length, car_width)\n",
    "push!(scene,Vehicle(vehstate1, vehdef1))\n",
    "carcolors[1] = colorant\"red\"\n",
    "\n",
    "track.models[2] = HRHC(2,track.roadway,context,h=12,v_max=125.0,μ=32.0,a_step=12.0,a_range=[-1,0,1],k=1)\n",
    "track.models[2].v_cmd = 70\n",
    "v₂ = track.models[2].v_range[track.models[2].v_cmd]\n",
    "vehstate2 = VehicleState(VecSE2(-160,-84,-1.0), track.roadway, v₂)\n",
    "vehdef2 = VehicleDef(2,AgentClass.CAR, car_length, car_width)\n",
    "push!(scene,Vehicle(vehstate2, vehdef2))\n",
    "carcolors[2] = colorant\"blue\"\n",
    "\n",
    "track.models[3] = HRHC(3,track.roadway,context,h=12,v_max=100.0,μ=25.0,a_step=12.0,a_range=[-1,0,1],k=3)\n",
    "track.models[3].v_cmd = 60\n",
    "v₃ = track.models[3].v_range[track.models[3].v_cmd]\n",
    "vehstate3 = VehicleState(VecSE2(-156,-70,-1.15), track.roadway, v₃)\n",
    "vehdef3 = VehicleDef(3,AgentClass.CAR, car_length, car_width)\n",
    "push!(scene,Vehicle(vehstate3, vehdef3))\n",
    "carcolors[3] = colorant\"yellow\"\n",
    "\n",
    "actions = Array(DriveAction, length(scene))\n",
    "\n",
    "track.obstacleMap = generateObstacleMap(scene, track.models)\n",
    "track;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0733ee01-4cae-4479-9418-83ed5b4bc599"
    }
   },
   "source": [
    "# Level K Racing\n",
    "\n",
    "### Continuous State Space\n",
    "Agents in Level-K Racing operate with a continuous state space. At each time step, the agent observes its state \n",
    "\n",
    "$$s = (x,y,\\theta,v,s,t,\\phi),$$\n",
    "\n",
    "where $x,y,\\theta$ are the global coordinates and yaw angle of the vehicle,\n",
    "$v$ is the tangential velocity of the vehicle, \n",
    "$s$ is the distance along the track centerline of the vehicle's center of mass,\n",
    "$t$ is the vehicle's lateral (normal) displacement from the centerline,\n",
    "$\\phi$ is the car's yaw angle relative to the track centerline. The vehicle also observes the same state information for all other vehicles on the track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DemoState(track,scene,carcolors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "598baa0d-eff4-453b-a87b-20fbdcfff1de"
    }
   },
   "source": [
    "### Discrete Action Space\n",
    "After observing the current state, the agent executes an action:\n",
    "\n",
    "$$a = (\\Delta v, \\delta)$$\n",
    "\n",
    "where $\\Delta v$ and $\\delta$ are chosen from a finite set of options:\n",
    "$$\\Delta v \\in \\left[ -\\Delta v_{max}, \\cdots, 0, \\cdots, \\Delta v_{max} \\right], $$ $$ \\delta \\in \\left[-\\delta_{max}, \\cdots, 0, \\cdots, \\delta_{max} \\right]$$\n",
    "\n",
    "Thus, the number of actions to choose from at a given time step is $|\\mathcal{A}| = |\\mathcal{V}| \\times |\\mathcal{\\delta}|$. In this particular implementation, there are only three options for acceleration: $\\Delta v \\in \\left[ -\\Delta v_{max}, 0, \\Delta v_{max} \\right]$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fe7937dd-1e33-4ef7-a01e-301989238537"
    }
   },
   "source": [
    "### State Transition Update\n",
    "The state of the vehicle evolves  deterministically as a function of the selected action. The position update equations are based on the bicycle kinematic model with a no-slip constraint. These equations can be found in the function $HierarchicalRecedingHorizonController.generateMotionMap()$. Bear in mind that the update equations are calculated assuming an initial yaw angle of zero. Obviously a coordinate transformation is necessary to compute the actual state update. \n",
    "\n",
    "The update rules for velocity and steering angle are given here:\n",
    "\n",
    "\\begin{align*}\n",
    "& v_{t_{n}} = v_{t_{n-1}} + \\Delta v & 0 \\leq v \\leq v_{max} & \\\\\n",
    "& \\delta_{t_{n}} = \\delta & |\\delta| < \\delta_{max}(v)\n",
    "\\end{align*}\n",
    "\n",
    "$\\delta_{max}$ is a function of the vehicle's current velocity, and represents the steering angle above which tire saturation (slipping) would occur.\n",
    "If the constraints are violated, $v$ and/or $\\delta$ are thresholded accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ed978f6-3354-42b1-8e3c-4d69c03cf4b7"
    }
   },
   "source": [
    "### Motion Primitives for Trajectory Planning\n",
    "\n",
    "The motion primitives represent feasible trajectories over the planning horizon $h$. These candidate trajectories are computed offline and stored in a dictionary, $HRHC.motion\\_map$, which is accessed by the index of the agent's current velocity. Thus, at velocity 50, the agent uses the candidate trajectories calculated for that velocity in its planning. \n",
    "\n",
    "The number of candidate trajectories calculated for each starting velocity is equal to the number of possible actions $\\mathcal{A}$ Each candidate trajectory is computed offline in the following manner: \n",
    "\n",
    "Begin at an initial velocity $v_{t_0}$\n",
    "\n",
    "For $\\Delta v \\in \\left[-\\Delta v_{max}, 0, \\Delta v_{max} \\right]$:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; \n",
    "For $\\delta \\in \\left[-\\delta_{max}, \\cdots, 0, \\cdots, \\delta_{max} \\right]$:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \n",
    "For $i \\in \\left[0, 1, \\cdots, h-1, h \\right]$:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$ v_{t_{i}} = v_{t_{i-1}} + \\Delta v $\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "$ \\delta_{t_{i}} = \\delta $\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "Update $x,y,\\theta$ according to update rules in $HierarchicalRecedingHorizonController.generateMotionMap()$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \n",
    "End\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "End\n",
    "\n",
    "End\n",
    "\n",
    "If $|\\delta| > \\delta_{max}(v)$, $\\delta$ is thresholded to $\\delta_{max}$ and  $\\Delta v$ is set to $ -\\Delta v_{max}$. Thus, the velocity continuously decreases for that candidate trajectory until the desired steering angle is reachable. This behavior is demonstrated in the second demo below, with a high starting velocity and a long planning horizon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "2f82122f-c1f6-4def-acb7-728603d9ace0"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize candidate trajectories for several different velocities\n",
    "DemoMotionPrimitives(track,context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "b05398fb-1d35-41bf-9379-e73088b83fbc"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize candidate trajectories for an increased planning horizon\n",
    "DemoIncreasedHorizonBehavior(track,context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a649d769-f3c8-469a-992e-5ab0edd6d820"
    }
   },
   "source": [
    "### Reward Shaping: Building the Objective Function\n",
    "With candidate trajectories for every reachable velocity, the agent can plan ahead $h$ time steps and select the action expected to maximize future reward. The idea is to reward progress along the track (measured by $\\Delta s$) while penalizing the states where the vehicle would be too close to the track boundaries. One key aspect of the objective function is that it imposes a penalty for yaw angle in the same direction as the lateral displacement from the centerline. For example, there is a very high penalty for being on the left side of the track AND angling left. Intuitively, this is a bad situation because it means the vehicle is about to drive off the left side of the track. There is a much lower penalty for being on the left side of the track and angling right (because the vehicle is driving back to the center).  In this approach, the reward function to be maximized is replaced with a cost function to be minimized. Here are the building blocks of the objective function:\n",
    "\n",
    "##### Incentivize progress along the track\n",
    "\n",
    "$$ Obj(s) = \\Big(\\frac{s}{s-s_0}\\Big),$$\n",
    "where $s_0$ is the vehicle's current $s$ value.\n",
    "\n",
    "#### Penalize being too close to the edge of the track\n",
    "\n",
    "$$ Obj(t) = \\Big(\\frac{t}{T_{max}}\\Big)^6$$\n",
    "Note that the maximum penalty is $1.0$. The idea here is that the penalty only becomes large when the vehicle is VERY close to the edge of the track.\n",
    "\n",
    "#### Penalize high yaw angle\n",
    "\n",
    "$$ Obj(t) = \\Big(\\frac{\\phi}{\\phi_{max}}\\Big)^6,$$\n",
    "Where $\\phi_{max} = \\pi$. The idea is to penalize driving in a direction no aligned with the track centerline.\n",
    "\n",
    "#### Penalize being too close to the edge of the track AND driving off the track\n",
    "\n",
    "$$ Obj(t,\\phi) = p^T A p,$$\n",
    "where \n",
    "$$\n",
    "p = \n",
    "\\begin{bmatrix}\n",
    "\\frac{t}{T_{max}}\\\\\n",
    "\\frac{\\phi}{\\phi_{max}} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "1 & .5 \\\\\n",
    ".5 & 0 \\\\\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "#### Full objective function\n",
    "The complete objective function is simply a linear combination of the above objectives:\n",
    "\n",
    "$$ Obj(s,t,\\phi) = c_s Obj(s) + c_t Obj(t) + c_\\phi Obj(\\phi) + c_{t,\\phi} Obj(t,\\phi)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d37694fd-150a-48ed-a247-86d06edaafa5"
    }
   },
   "outputs": [],
   "source": [
    "DemoBuildingBlocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "b5537bdf-1422-4e98-a848-a9dd9c899ec8"
    }
   },
   "outputs": [],
   "source": [
    "# Heat map of the objective function \n",
    "# Modify t_shift to see how the objective function changeswhen the car is closer to the edge of the road\n",
    "t_shift = 0\n",
    "DemoObjective(t_shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "01236c61-01de-4e9b-8f0f-e92cf17ac85d"
    }
   },
   "source": [
    "# Cost of Collision\n",
    "\n",
    "The one thing missing from the objective function is a penalty, $Obj_{collision}$, for collision with other vehicles. This value is calculated as follows:\n",
    "\n",
    "\n",
    "#### Draw Bounding Ellipse\n",
    "\n",
    "Draw an ellipse around each vehicle. The semi-major axes of the ellipse are computed by finding the ellipse of minimum area that completely encloses the vehicle. I won't go through the full derivation here, but semi-major axes $A$ and $B$ are defined as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "& B = \\sqrt{\\frac{-b + \\sqrt{b^2 - 4*a*c}}{2*a}} & \\\\\n",
    "& A = \\sqrt{\\frac{W^2}{1 - \\big(\\frac{L}{B}\\big)^2}}\n",
    "\\end{align*}\n",
    "\n",
    "where $ a = 2$, $ b = -4 L - 2 W^2 L^2 $, $ c = 2 L^4 $, where $L$ is the length of the vehicle and $W$ is the width of the vehicle. The equation for B is recognizable as the quadratic equation, but in this case we are solving for $B^2$ (hence we take the square root of the whole quantity to obtain $B$).\n",
    "\n",
    "#### Check for overlap of bounding ellipses\n",
    "\n",
    "This is not a fool proof overlap checker, but it does a good job of determining when collisions are expected. It works as follows:\n",
    "\n",
    "Calculate the distance between the two vehicles (center to center):\n",
    "\n",
    "$$ R = \\sqrt{\\Delta x^2 + \\Delta y^2} $$\n",
    "\n",
    "Calculate the angular offset between the vehicles\n",
    "\n",
    "$$ \\zeta = atan2(\\Delta y, \\Delta x) $$\n",
    "\n",
    "Calculate the difference between the angular offset and the heading offset:\n",
    "\n",
    "$$ \\psi = \\zeta - \\theta_2 - \\theta_1 $$\n",
    "\n",
    "Calculate the elliptical radii along the line between the two vehicles' centers:\n",
    "\n",
    "$$ r_1 = \\frac{W L}{\\sqrt{L^2 sin(\\zeta)^2 + W^2 cos(\\zeta)^2}} $$\n",
    "$$ r_2 = \\frac{W L}{\\sqrt{L^2 sin(\\psi)^2 + W^2 cos(\\psi)^2}} $$\n",
    "\n",
    "If $ r_1 + r_2 \\geq R \\Rightarrow Overlap \\Rightarrow Collision $\n",
    "\n",
    "#### Penalty for Collision\n",
    "When a collision is predicted, the objective function is set to $\\inf$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "cd05e933-3cd3-4666-a867-7afa8d317d0c"
    }
   },
   "source": [
    "# Other Objective Function Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e52973f1-7c51-49ca-88b1-9e6b48010ca6"
    }
   },
   "source": [
    "#### Fixing the Tailgating Problem\n",
    "\n",
    "It turns out that cars get \"stuck\" behind each other. To fix this, I have added a penalty to the objective function that discourages tailgating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "eb4b9c72-84c3-45d8-8d7d-19bfa44ccdaf"
    }
   },
   "outputs": [],
   "source": [
    "x,y,Rψ_cost = DemoTailgateAvoidance()\n",
    "Rψ_cost;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "391df5f7-c630-4786-8c87-50782c51367d"
    }
   },
   "outputs": [],
   "source": [
    "PyPlot.scatter3D(x,y,Rψ_cost,c=Rψ_cost,edgecolor=\"none\")\n",
    "# PyPlot.axis(\"off\")\n",
    "PyPlot.title(\"3D visualization of cost(R,psi)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e1db1f35-14d8-4f81-8d13-59189ccab518"
    }
   },
   "source": [
    "## Objective Function in Action\n",
    "\n",
    "The agents determine which action to take by calculating the cost of each candidate trajectory, throwing out all trajectories expected to yield a collision, then selecting the optimal trajectory with respect to the objective function. It then executes the associated action for one time step and repeats the planning process.  You can watch the vehicle(s) planning and executing by running the following cell repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "863d9cfa-211e-4210-a9b2-f153fa271a5c"
    }
   },
   "outputs": [],
   "source": [
    "DemoObserveActObjective(track,scene,steps=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Level-K Reasoning\n",
    "\n",
    "Each agent on the track has an associated logit level equal to or greater than 1. Level 1 cars assume all other cars reason at level 0 (unaware of other vehicles), level 2 cars assume all other cars reason at level 1, etc. The enabling data structure for this reasoning is a nested Dictionary called $track.obstacleMap$. It stores the selected optimal trajectories for every car at every level. There is no uncertainty (yet!) in the state, so these are the actual trajectories that will be followed by the vehicles of the corrseponding logit level for the next time step.\n",
    "The trajectories can be visualized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_level = 1\n",
    "DemoObstacleMap(track,k_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "\n",
    "There are a whole lot of cool things that can be done with this. The value function could be learned rather than hand-crafted. Obviously we'll want to introduce uncertainty and partial visibility into the problem. I'll be moving on to other projects, but let me know if you'd like to get involved in taking this project forward!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  },
  "nbpresent": {
   "slides": {
    "f62a5563-8755-4a81-b6fe-3ae0592ff816": {
     "id": "f62a5563-8755-4a81-b6fe-3ae0592ff816",
     "prev": null,
     "regions": {
      "6bdcdc6f-d1ef-4638-9e97-97b461d4e27d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8000000000000002,
        "x": 0.10000000000000002,
        "y": 0.1
       },
       "content": {
        "cell": "831c489a-993a-402f-9f41-468222ed2c7a",
        "part": "outputs"
       },
       "id": "6bdcdc6f-d1ef-4638-9e97-97b461d4e27d"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
